# üîî Zolt Summarizer

O **Zolt Summarizer** √© uma ferramenta robusta de processamento de √°udio concebida para transformar grava√ß√µes de reuni√µes e conversas em resumos inteligentes e estruturados.

O pipeline integra tecnologias de ponta para realizar a transcri√ß√£o (Whisper), identifica√ß√£o de oradores (Pyannote) e gera√ß√£o de resumos atrav√©s de LLMs locais (Ollama).

## üöÄ Funcionalidades Principais

  * **Transcri√ß√£o de Alta Precis√£o:** Utiliza o modelo **Whisper** (OpenAI) para converter √°udio em texto.
  * **Diariza√ß√£o de Oradores:** Identifica "quem falou o que" utilizando o **Pyannote Audio**.
  * **Resumos com IA Local:** Integra√ß√£o com o **Ollama** para gerar resumos utilizando modelos como Llama3 ou Qwen.
  * **Pipeline Modular:** Sistema orquestrado pelo m√≥dulo `ArcanaFlow` (Nayahath) para logs detalhados e gest√£o de fluxo.

## üìã Pr√©-requisitos

Para executar este projeto, necessitar√° de ter instalado:

  * [Docker](https://www.docker.com/) e Docker Compose
  * [FFmpeg](https://ffmpeg.org/) (recomendado para manipula√ß√£o de ficheiros de √°udio)
  * Uma conta no **Hugging Face** e um token de acesso (para descarregar os modelos do Pyannote).

## üõ†Ô∏è Instala√ß√£o e Configura√ß√£o

### 1\. Preparar o Ambiente Docker

O projeto utiliza o Docker para gerir as depend√™ncias do Python e o servi√ßo do Ollama.

Clone o reposit√≥rio e construa os contentores:

```bash
docker-compose up -d --build
```

Este comando ir√° iniciar dois servi√ßos:

  * `zolt_summarizer`: O ambiente Python com as bibliotecas necess√°rias.
  * `ollama_backend`: O servidor para os modelos de linguagem.

### 2\. Configurar o Modelo de IA (Ollama)

Antes de iniciar o resumo, √© necess√°rio descarregar o modelo de linguagem que deseja utilizar (ex: llama3, qwen, mistral). Execute o seguinte comando para descarregar e testar o modelo:

```bash
docker exec -it ollama_backend ollama run llama3
```

> **Nota:** Pode substituir `llama3` por qualquer outro modelo dispon√≠vel na biblioteca do Ollama.
> Para sair do chat do Ollama, digite `/bye`.

![teste ollama](./readme_images/image.png)

### 3\. Configurar o Projeto (`zolt_config.py`)

Edite o ficheiro `zolt_config.py` na raiz do projeto com as suas configura√ß√µes:

```python
HUGGING_FACE_TOKEN="O_SEU_TOKEN_HUGGING_FACE"  # Necess√°rio para o Pyannote
FILE_PATH="./caminho/para/o/seu_audio.wav"     # O ficheiro de √°udio a processar
SUMMARIZER_MODEL="llama3"                      # O modelo que descarregou no passo anterior
TIMESTAMPS=False                               # Definir como True para incluir carimbos de tempo no resumo
```

> **Importante:** O Pyannote requer que aceite os termos de utiliza√ß√£o dos modelos `pyannote/speaker-diarization` e `pyannote/segmentation` no site do Hugging Face para que o seu token funcione.

## ‚ñ∂Ô∏è Como Utilizar

### 1\. Aceder ao Contentor

Entre no terminal do contentor principal onde o script ser√° executado:

```bash
docker exec -it zolt_summarizer /bin/bash
```

### 2\. Instalar Depend√™ncias

Garanta que todas as bibliotecas Python est√£o atualizadas:

```bash
pip install -r requirements.txt
```

### 3\. Executar o Pipeline

Inicie o processo de sumariza√ß√£o executando o script principal:

```bash
python flow.py
```

O sistema, gerido pela entidade "Nayahath", ir√° apresentar o progresso no terminal, passando pela diariza√ß√£o, transcri√ß√£o e, finalmente, o resumo.

üìÇ **Resultados:** Os ficheiros gerados (transcri√ß√µes e resumos) ser√£o guardados na diretoria `outputs/`, organizados por data e hora.

-----

## üß© Arquitetura do Sistema

O Zolt Summarizer √© composto por quatro entidades principais que colaboram para gerar o resultado final:

1.  **üü£ Nayahath (ArcanaFlow):**
    A coordenadora do sistema. √â respons√°vel por gerir o fluxo de execu√ß√£o, instanciar as interfaces e apresentar os logs coloridos e detalhados no terminal.

2.  **üîµ Diarizer:**
    Respons√°vel por identificar os oradores. Utiliza o **Pyannote** para segmentar o √°udio e atribuir etiquetas (ex: SPEAKER\_00, SPEAKER\_01) a cada intervalo de fala.

3.  **üü¢ Transcripter:**
    Utiliza o **Whisper** (modelo `turbo` por defeito) para converter o √°udio em texto bruto, ignorando quem est√° a falar e focando-se apenas no conte√∫do.

4.  **üü° Summarizer:**
    Recebe os dados sincronizados do *Diarizer* e do *Transcripter*. Envia o texto estruturado para o **Ollama**, instruindo o modelo a gerar um resumo contextualizado, atas ou responder a perguntas espec√≠ficas sobre a conversa.

-----

## üí° Dicas √öteis

### Extrair √°udio de v√≠deo

Se tiver uma grava√ß√£o em v√≠deo (MP4), utilize o **FFmpeg** para extrair o √°udio no formato correto (WAV 16kHz mono) antes de o processar:

```bash
ffmpeg -i "video_reuniao.mp4" -vn -acodec pcm_s16le -ar 16000 -ac 1 "audio_processado.wav"
```

### Testar apenas o Resumo

Se j√° tiver o texto transcrito e quiser apenas testar diferentes prompts ou modelos de LLM sem reprocessar o √°udio, pode editar e executar o script de teste:

```bash
python teste_ollama.py
```